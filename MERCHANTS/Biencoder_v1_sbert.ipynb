{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look into architechture modification and add numerical values as concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers\n",
    "%pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import umap\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"drive/MyDrive/DATA_transactions/2024_05_20_sample_pairs.csv\", index_col = None)\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate = df_data[0:100]\n",
    "df_test = df_data[100:200]\n",
    "df_train = df_data[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_embedding_model = models.Transformer(\"bert-base-uncased\", max_seq_length=256)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['label'] = df_data['label'].astype('float32')\n",
    "df_data['true_label'] = df_data['true_label'].astype('float32')\n",
    "train_examples = [InputExample(texts = [df_data.loc[i,'sentence'], df_data.loc[i,'merchant_name_combined']], label=df_data.loc[i,'true_label']  ) for i in range(df_data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.CosineSimilarityLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_objectives = [(train_dataloader, train_loss)], epochs =5 , warmup_steps = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data = df_data.sample(30, random_state = 100)\n",
    "trx_descriptions = validate_data['sentence'].tolist()\n",
    "merchants = validate_data['merchant_name_combined'].tolist()\n",
    "trx_embeddings = model.encode(trx_descriptions)\n",
    "merchants_embeddings = model.encode(merchants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trx_embeddings.shape)\n",
    "print(merchants_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## look into numba\n",
    "cosine_similarity(trx_embeddings, merchants_embeddings).shape\n",
    "validate_data['cos_similarity']=np.diag(cosine_similarity(trx_embeddings, merchants_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data[['label', 'true_label','cos_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer = umap.UMAP(n_epochs=400,  n_neighbors=150, min_dist=0.1)\n",
    "# reducer.fit(merchants_embeddings\n",
    "# )\n",
    "# embedding_2d = reducer.transform(merchants_embeddings)\n",
    "# fig = px.scatter(embedding_2d, x=0, y=1,opacity=0.05, height=500, hover_name=names)\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvdataexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
