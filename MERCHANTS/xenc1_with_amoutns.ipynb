{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplication 2nd step  pointwise (with amounts)\n",
    "\n",
    "sentence 1 = Take TX + merchant1, \n",
    "\n",
    "sentence 2 = Take TX + merchant2\n",
    "\n",
    "label =1 , if merchant 1 = m2\n",
    "\n",
    "\n",
    "\n",
    "The candidate duplicates for merchant 1 should be retrieved from a first candidate selection step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train a classification model  TX <m1> merchant1 <m2> merchant2 = 1,0\n",
    "\n",
    "- Train a classification model  TX <m1> merchant1, amount m1 <m2> merchant2, amount 2 (to deduplicate existing merchant table) \n",
    "\n",
    "- train a binary classification model\n",
    "\n",
    "\n",
    "- look into architechture modification and add numerical values as concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sbert.net/docs/sentence_transformer/training_overview.html#dataset-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awswrangler in /opt/conda/lib/python3.10/site-packages (3.8.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.32 in /opt/conda/lib/python3.10/site-packages (from awswrangler) (1.34.51)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /opt/conda/lib/python3.10/site-packages (from awswrangler) (1.34.51)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in /opt/conda/lib/python3.10/site-packages (from awswrangler) (1.26.4)\n",
      "Requirement already satisfied: packaging<25.0,>=21.1 in /opt/conda/lib/python3.10/site-packages (from awswrangler) (23.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler) (2.1.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler) (12.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from awswrangler) (4.5.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (2.9.0)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (1.26.18)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_path_training_data = \"s3://cleo-data-science/transaction_enrichment/experimental_data/caste/cross_encoder/xenc1/train_cons_2024-05-15_2024-05-18_1.parquet\"\n",
    "# df_train = wr.s3.read_parquet(s3_path_training_data)\n",
    "# print(df_train.shape[0])\n",
    "# #-------------\n",
    "# s3_path_test_data = \"s3://cleo-data-science/transaction_enrichment/experimental_data/caste/cross_encoder/xenc1/test_cons_2024-05-15_2024-05-18_1.parquet\"\n",
    "# df_test = wr.s3.read_parquet(s3_path_test_data)\n",
    "# print(df_test.shape[0])\n",
    "\n",
    "\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "# ds_train = Dataset.from_pandas(df_train[[label_col,text_col]])\n",
    "# ds_test = Dataset.from_pandas(df_test[[label_col,text_col]])\n",
    "ds_train = load_from_disk('/home/sagemaker-user/data/xencdups2/train_dataset')\n",
    "ds_test = load_from_disk('/home/sagemaker-user/data/xencdups2/test_dataset')\n",
    "ds_val = load_from_disk('/home/sagemaker-user/data/xencdups2/val_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'label'\n",
    "text_col = 'text'\n",
    "\n",
    "# ds_train.save_to_disk('/home/sagemaker-user/data/xencdups/train_dataset')\n",
    "# ds_test.save_to_disk('/home/sagemaker-user/data/xencdups/test_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load duplicates_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_duplicates_candidates = wr.s3.read_csv(\"s3://cleo-data-science/transaction_enrichment/experimental_data/caste/embedding_predictions/model9/checkpoint-7800/duplicate_merchant_matching_candidates_N_10_cons_2024-05-15_2024-05-18_1.csv\", index_col=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_duplicates_candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     df_duplicates_candidates.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_path = \"s3://cleo-data-science/transaction_enrichment/experimental_data/caste/trx-merchant-pair/cons_2024-05-15_2024-05-18_1.parquet/\"\n",
    "\n",
    "\n",
    "# df_data_raw = wr.s3.read_parquet(path=s3_path)\n",
    "# df_data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_list = ['DoorDash','Savings','Overdraft Charge','Withdrawal','PayPal','Point Of Sale Withdrawal', 'Adjustment','Cash Withdrawal','Chime','Doordash','Signature','Sezzle'\n",
    "#  'Zelle',\n",
    "#  'Chase Bank',\n",
    "#  'Cash App',\n",
    "#  'Wells Fargo',\n",
    "#  'Capital One',\n",
    "#  'Google Play Store',\n",
    "#  'Square',\n",
    "#  'DoorDash',\n",
    "#  'Citibank',\n",
    "#  'Toast',\n",
    "#  'Instacart',\n",
    "#  'Apple Cash',\n",
    "#  'Credit',\n",
    "#  'Earnin',\n",
    "#  'Klover App','Klarna','Savings','Insufficient Funds / Failed Transaction Fee','Point Of Sale Deposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 314.61 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Process.memory_info is expressed in bytes, so convert to megabytes\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1.0,\n",
       " 'text': 'Merchant: #1 Wake County Abc TX: #4 Wake County Abc Boar Amount: -15.7 |SEP| Merchant: Wake County Abc Boa TX: #21 Wake County Abc Boa Amount: -19.2'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 314.61 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Process.memory_info is expressed in bytes, so convert to megabytes\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1178839"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1.0,\n",
       " 'text': 'Merchant: #1 Wake County Abc TX: #4 Wake County Abc Boar Amount: -15.7 |SEP| Merchant: Wake County Abc Boa TX: #21 Wake County Abc Boa Amount: -19.2'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22271065005484209"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ds_train[label_col]).sum()/len(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22132594496978025"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ds_test[label_col]).sum()/len(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"google-bert/bert-base-cased\"\n",
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428c5bd5f54b4e628caba47a80b128a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1178839 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 1.0,\n",
       "  'text': 'Merchant: #1 Wake County Abc TX: #4 Wake County Abc Boar Amount: -15.7 |SEP| Merchant: Wake County Abc Boa TX: #21 Wake County Abc Boa Amount: -19.2',\n",
       "  'input_ids': [101,\n",
       "   6432,\n",
       "   1024,\n",
       "   1001,\n",
       "   1015,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   19067,\n",
       "   1024,\n",
       "   1001,\n",
       "   1018,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   24187,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   2321,\n",
       "   1012,\n",
       "   1021,\n",
       "   1064,\n",
       "   19802,\n",
       "   1064,\n",
       "   6432,\n",
       "   1024,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   19067,\n",
       "   1024,\n",
       "   1001,\n",
       "   2538,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   2539,\n",
       "   1012,\n",
       "   1016,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'attention_mask': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]},\n",
       " {'label': 1.0,\n",
       "  'text': 'Merchant: #1 Wake County Abc TX: #3 WAKE COUNTY ABC BOAR MORRISVILLE NC Amount: -42.8 |SEP| Merchant: Wake County Abc Boa TX: #21 Wake County Abc Boa Amount: -19.2',\n",
       "  'input_ids': [101,\n",
       "   6432,\n",
       "   1024,\n",
       "   1001,\n",
       "   1015,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   19067,\n",
       "   1024,\n",
       "   1001,\n",
       "   1017,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   24187,\n",
       "   6384,\n",
       "   3077,\n",
       "   13316,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   4413,\n",
       "   1012,\n",
       "   1022,\n",
       "   1064,\n",
       "   19802,\n",
       "   1064,\n",
       "   6432,\n",
       "   1024,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   19067,\n",
       "   1024,\n",
       "   1001,\n",
       "   2538,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   2539,\n",
       "   1012,\n",
       "   1016,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'attention_mask': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]},\n",
       " {'label': 1.0,\n",
       "  'text': 'Merchant: #1 Wake County Abc TX: #3 Wake County Abc Boar Amount: -15.1 |SEP| Merchant: Wake County Abc Boa TX: #21 Wake County Abc Boa Amount: -19.2',\n",
       "  'input_ids': [101,\n",
       "   6432,\n",
       "   1024,\n",
       "   1001,\n",
       "   1015,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   19067,\n",
       "   1024,\n",
       "   1001,\n",
       "   1017,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   24187,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   2321,\n",
       "   1012,\n",
       "   1015,\n",
       "   1064,\n",
       "   19802,\n",
       "   1064,\n",
       "   6432,\n",
       "   1024,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   19067,\n",
       "   1024,\n",
       "   1001,\n",
       "   2538,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   2539,\n",
       "   1012,\n",
       "   1016,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'attention_mask': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]},\n",
       " {'label': 1.0,\n",
       "  'text': 'Merchant: #1 Wake County Abc TX: Purchase #4 WAKE COUNTY ABC BOA RALEIGH NCUS Amount: -24.6 |SEP| Merchant: Wake County Abc Boa TX: #21 Wake County Abc Boa Amount: -19.2',\n",
       "  'input_ids': [101,\n",
       "   6432,\n",
       "   1024,\n",
       "   1001,\n",
       "   1015,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   19067,\n",
       "   1024,\n",
       "   5309,\n",
       "   1001,\n",
       "   1018,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   15842,\n",
       "   13316,\n",
       "   2271,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   2484,\n",
       "   1012,\n",
       "   1020,\n",
       "   1064,\n",
       "   19802,\n",
       "   1064,\n",
       "   6432,\n",
       "   1024,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   19067,\n",
       "   1024,\n",
       "   1001,\n",
       "   2538,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   2539,\n",
       "   1012,\n",
       "   1016,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'attention_mask': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]},\n",
       " {'label': 1.0,\n",
       "  'text': 'Merchant: #1 Wake County Abc TX: 3 WAKE COUNTY ABC BOA Amount: -13.9 |SEP| Merchant: Wake County Abc Boa TX: #21 Wake County Abc Boa Amount: -19.2',\n",
       "  'input_ids': [101,\n",
       "   6432,\n",
       "   1024,\n",
       "   1001,\n",
       "   1015,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   19067,\n",
       "   1024,\n",
       "   1017,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   2410,\n",
       "   1012,\n",
       "   1023,\n",
       "   1064,\n",
       "   19802,\n",
       "   1064,\n",
       "   6432,\n",
       "   1024,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   19067,\n",
       "   1024,\n",
       "   1001,\n",
       "   2538,\n",
       "   5256,\n",
       "   2221,\n",
       "   5925,\n",
       "   8945,\n",
       "   2050,\n",
       "   3815,\n",
       "   1024,\n",
       "   1011,\n",
       "   2539,\n",
       "   1012,\n",
       "   1016,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'attention_mask': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenized_ds_train = ds_test.map(tokenize_function, batched=True)\n",
    "tokenized_ds_train = ds_train.map(tokenize_function, batched=True)\n",
    "dataset_head = tokenized_ds_train.take(5)\n",
    "list(dataset_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 929.10 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install zstandard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds_val = ds_val.map(tokenize_function, batched=True)\n",
    "#tokenized_ds_test = ds_test.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 17:40:24.051905: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 1517.59 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "#metric = evaluate.load(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"/home/sagemaker-user/models/xenc3\", evaluation_strategy=\"steps\", \\\n",
    "    num_train_epochs=1, per_device_train_batch_size=32, per_device_eval_batch_size=32, \\\n",
    "         eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=100,\n",
    "    logging_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedTokenizerBase.pad of DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_sentences = [len(x) for x in  ds_train['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lens_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_ds_train[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds_train,\n",
    "    eval_dataset=tokenized_ds_val\n",
    "    #compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_sm_patterns_to_gitignore',\n",
       " '_created_lr_scheduler',\n",
       " '_gather_and_numpify',\n",
       " '_get_collator_with_removed_columns',\n",
       " '_get_eval_sampler',\n",
       " '_get_learning_rate',\n",
       " '_get_output_dir',\n",
       " '_get_train_sampler',\n",
       " '_hp_search_setup',\n",
       " '_inner_training_loop',\n",
       " '_issue_warnings_after_load',\n",
       " '_load_best_model',\n",
       " '_load_from_checkpoint',\n",
       " '_load_optimizer_and_scheduler',\n",
       " '_load_rng_state',\n",
       " '_loggers_initialized',\n",
       " '_maybe_log_save_evaluate',\n",
       " '_memory_tracker',\n",
       " '_move_model_to_device',\n",
       " '_nested_gather',\n",
       " '_prepare_input',\n",
       " '_prepare_inputs',\n",
       " '_push_from_checkpoint',\n",
       " '_remove_unused_columns',\n",
       " '_report_to_hp_search',\n",
       " '_rotate_checkpoints',\n",
       " '_save',\n",
       " '_save_checkpoint',\n",
       " '_save_tpu',\n",
       " '_set_signature_columns_if_needed',\n",
       " '_signature_columns',\n",
       " '_sorted_checkpoints',\n",
       " '_train_batch_size',\n",
       " '_tune_save_checkpoint',\n",
       " '_wrap_model',\n",
       " 'accelerator',\n",
       " 'add_callback',\n",
       " 'args',\n",
       " 'autocast_smart_context_manager',\n",
       " 'call_model_init',\n",
       " 'callback_handler',\n",
       " 'can_return_loss',\n",
       " 'compute_loss',\n",
       " 'compute_loss_context_manager',\n",
       " 'compute_metrics',\n",
       " 'control',\n",
       " 'create_accelerator_and_postprocess',\n",
       " 'create_model_card',\n",
       " 'create_optimizer',\n",
       " 'create_optimizer_and_scheduler',\n",
       " 'create_scheduler',\n",
       " 'current_flos',\n",
       " 'data_collator',\n",
       " 'deepspeed',\n",
       " 'do_grad_scaling',\n",
       " 'eval_dataset',\n",
       " 'evaluate',\n",
       " 'evaluation_loop',\n",
       " 'floating_point_ops',\n",
       " 'fsdp',\n",
       " 'get_eval_dataloader',\n",
       " 'get_optimizer_cls_and_kwargs',\n",
       " 'get_test_dataloader',\n",
       " 'get_train_dataloader',\n",
       " 'hp_name',\n",
       " 'hp_search_backend',\n",
       " 'hyperparameter_search',\n",
       " 'init_git_repo',\n",
       " 'ipex_optimize_model',\n",
       " 'is_deepspeed_enabled',\n",
       " 'is_fsdp_enabled',\n",
       " 'is_in_train',\n",
       " 'is_local_process_zero',\n",
       " 'is_model_parallel',\n",
       " 'is_world_process_zero',\n",
       " 'label_names',\n",
       " 'label_smoother',\n",
       " 'log',\n",
       " 'log_metrics',\n",
       " 'lr_scheduler',\n",
       " 'metrics_format',\n",
       " 'model',\n",
       " 'model_init',\n",
       " 'model_wrapped',\n",
       " 'num_examples',\n",
       " 'optimizer',\n",
       " 'place_model_on_device',\n",
       " 'pop_callback',\n",
       " 'predict',\n",
       " 'prediction_loop',\n",
       " 'prediction_step',\n",
       " 'preprocess_logits_for_metrics',\n",
       " 'push_to_hub',\n",
       " 'remove_callback',\n",
       " 'save_metrics',\n",
       " 'save_model',\n",
       " 'save_state',\n",
       " 'sharded_ddp',\n",
       " 'state',\n",
       " 'store_flos',\n",
       " 'tokenizer',\n",
       " 'torch_jit_model_eval',\n",
       " 'train',\n",
       " 'train_dataset',\n",
       " 'training_step',\n",
       " 'use_apex',\n",
       " 'use_cpu_amp',\n",
       " 'use_cuda_amp',\n",
       " 'use_tune_checkpoints']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4517' max='36839' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4517/36839 5:08:07 < 36:45:45, 0.24 it/s, Epoch 0.12/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.116260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.114795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.132906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.121462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.119877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.134752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.136594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.138576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.122093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/exploration/MERCHANTS/xenc1_with_amoutns.ipynb Cell 48\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ugu5gr0a4s03q5o.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/xenc1_with_amoutns.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1544\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1809\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1808\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1809\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1811\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1812\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1813\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1814\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1815\u001b[0m ):\n\u001b[1;32m   1816\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2665\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2663\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2664\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2665\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m   2667\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:1853\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1852\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1853\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 or 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"/home/sagemaker-user/models/xenc1/checkpoint-1500\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    #train_dataset=tokenized_ds_train,\n",
    "    eval_dataset=tokenized_ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237500"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237500"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_ds_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63b21fc407b4ac9887b3799df678a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_small = 10\n",
    "ds_val_small = Dataset.from_pandas(df_val[[label_col,text_col]][0:n_samples_small])\n",
    "tokenized_ds_val_small = ds_val_small.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "trainer_base = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    #train_dataset=tokenized_ds_train,\n",
    "    eval_dataset=tokenized_ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_original = trainer_base.predict(tokenized_ds_val_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.09304377],\n",
       "       [-0.06542447],\n",
       "       [-0.1722931 ],\n",
       "       [-0.11078063],\n",
       "       [-0.1245597 ],\n",
       "       [-0.16795816],\n",
       "       [-0.11878139],\n",
       "       [-0.12492839],\n",
       "       [-0.20494896],\n",
       "       [-0.19127694]], dtype=float32), label_ids=array([1., 1., 1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), metrics={'test_loss': 0.5251002907752991, 'test_accuracy': 0.6, 'test_runtime': 0.107, 'test_samples_per_second': 93.5, 'test_steps_per_second': 9.35})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_ds_val_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds_val_small['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9968817 ],\n",
       "       [ 0.9926137 ],\n",
       "       [ 0.99886316],\n",
       "       [-0.04816552],\n",
       "       [-0.03600875],\n",
       "       [-0.02542846],\n",
       "       [-0.03979023],\n",
       "       [-0.05198553],\n",
       "       [-0.03755949],\n",
       "       [ 0.9915965 ]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'transaction_id'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>label</th>\n",
       "      <th>transaction_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9803401833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.992614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9897551358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9785988152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.048166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9700042820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.036009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9987316761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.025428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9959855172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.039790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9713836600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.051986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9805702198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.037559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9915227855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.991597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9859792831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions  label  transaction_id\n",
       "0     0.996882    1.0      9803401833\n",
       "1     0.992614    1.0      9897551358\n",
       "2     0.998863    1.0      9785988152\n",
       "3    -0.048166    0.0      9700042820\n",
       "4    -0.036009    0.0      9987316761\n",
       "5    -0.025428    0.0      9959855172\n",
       "6    -0.039790    0.0      9713836600\n",
       "7    -0.051986    0.0      9805702198\n",
       "8    -0.037559    0.0      9915227855\n",
       "9     0.991597    1.0      9859792831"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions = pd.DataFrame(predictions[0], columns=['predictions'])\n",
    "df_predictions['label'] = ds_val_small['label']\n",
    "df_predictions['transaction_id'] = ds_val_small['transaction_id']\n",
    "#df_predictions.set_index('transaction_id', inplace=True)\n",
    "df_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Precision 1.0 Recall 1.0\n"
     ]
    }
   ],
   "source": [
    "th = 0.5\n",
    "pred_acc = (1*(df_predictions['predictions']>0.5) == df_predictions['label']).sum()/df_predictions.shape[0]\n",
    "true_positives = df_predictions[(df_predictions['label']==1) & (df_predictions['predictions']>=th)].shape[0]\n",
    "false_positives  = df_predictions[(df_predictions['label']==0) & (df_predictions['predictions']>=th)].shape[0]\n",
    "pred_precision = true_positives/(true_positives+false_positives)\n",
    "false_negatives = df_predictions[(df_predictions['label']==1) & (df_predictions['predictions']<th)].shape[0]\n",
    "print(pred_precision)\n",
    "pred_recall = true_positives/(true_positives + false_negatives)\n",
    "print(f\"Precision {pred_precision} Recall {pred_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://cleo-data-science/transaction_enrichment/experimental_data/caste/predictions_dedup/small_dataset'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_s3_output = \"s3://cleo-data-science/transaction_enrichment/experimental_data/caste/predictions_dedup/\"\n",
    "fname_s3_out = path_s3_output+\"small_dataset\"\n",
    "wr.s3.to_parquet(df_predictions, fname_s3_out)\n",
    "print(fname_s3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write predictions to s3 bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_val_small['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*(predictions[0]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=1*(predictions[0]>0.5), references=ds_val_small['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.9968817 ],\n",
       "       [ 0.9926137 ],\n",
       "       [ 0.99886316],\n",
       "       [-0.04816552],\n",
       "       [-0.03600875],\n",
       "       [-0.02542846],\n",
       "       [-0.03979023],\n",
       "       [-0.05198553],\n",
       "       [-0.03755949],\n",
       "       [ 0.9915965 ]], dtype=float32), label_ids=array([1., 1., 1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), metrics={'test_loss': 0.0010095818433910608, 'test_accuracy': 0.6, 'test_runtime': 0.1039, 'test_samples_per_second': 96.289, 'test_steps_per_second': 9.629})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0.0,\n",
       " 'text': 'RDS VENDING, LLC PHILADELPHIA [SEP] Rds Vending [SEP] Calmal Vending',\n",
       " 'transaction_id': 9915227855}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val_small[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9968817 ],\n",
       "       [ 0.9926137 ],\n",
       "       [ 0.99886316],\n",
       "       [-0.04816552],\n",
       "       [-0.03600875],\n",
       "       [-0.02542846],\n",
       "       [-0.03979023],\n",
       "       [-0.05198553],\n",
       "       [-0.03755949],\n",
       "       [ 0.9915965 ]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1.0,\n",
       " 'text': 'Betmgm Online [SEP] BetMGM.com [SEP] BetMGM',\n",
       " 'transaction_id': 9803401833}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val_small[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9968817 ],\n",
       "       [ 0.9926137 ],\n",
       "       [ 0.99886316],\n",
       "       [-0.04816552],\n",
       "       [-0.03600875],\n",
       "       [-0.02542846],\n",
       "       [-0.03979023],\n",
       "       [-0.05198553],\n",
       "       [-0.03755949],\n",
       "       [ 0.9915965 ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val_small['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.0010095818433910608,\n",
       " 'test_accuracy': 0.6,\n",
       " 'test_runtime': 0.1768,\n",
       " 'test_samples_per_second': 56.57,\n",
       " 'test_steps_per_second': 5.657}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.9964445 ],\n",
       "       [ 0.99798816],\n",
       "       [ 1.0009276 ],\n",
       "       ...,\n",
       "       [-0.01006407],\n",
       "       [-0.00524025],\n",
       "       [-0.00686787]], dtype=float32), label_ids=array([1., 1., 1., ..., 0., 0., 0.], dtype=float32), metrics={'test_loss': 0.006608151830732822, 'test_accuracy': 0.8007747368421053, 'test_runtime': 2329.7816, 'test_samples_per_second': 101.941, 'test_steps_per_second': 3.186})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert_xenc_no_amoutns.ipynb Cell 42\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://y7wv7jht4rw3qcj.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert_xenc_no_amoutns.ipynb#Y433sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mpredict(tokenized_datasets[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://y7wv7jht4rw3qcj.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert_xenc_no_amoutns.ipynb#Y433sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(predictions\u001b[39m.\u001b[39mpredictions\u001b[39m.\u001b[39mshape, predictions\u001b[39m.\u001b[39mlabel_ids\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finish here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(Dataset):\n",
    "    def __init__(self, dataframe, text_col, label_col):\n",
    "        self.dataframe = dataframe\n",
    "        self.text = dataframe[text_col].values  # Assuming 'target' is the label column\n",
    "        self.labels = dataframe[label_col].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx]\n",
    "        label = self.labels[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PandasDataset.__init__() missing 2 required positional arguments: 'text_col' and 'label_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert_clean2.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://mevoqhifxrgq2ey.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert_clean2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m PandasDataset(df_data_raw)\n",
      "\u001b[0;31mTypeError\u001b[0m: PandasDataset.__init__() missing 2 required positional arguments: 'text_col' and 'label_col'"
     ]
    }
   ],
   "source": [
    "# dataset = PandasDataset(df_data_raw, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-06-18 12:39:05.971559: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TokenizedPandasDataset(Dataset):\n",
    "#     def __init__(self, dataframe, tokenizer, text_column, label_column):\n",
    "#         self.dataframe = dataframe\n",
    "#         self.text = dataframe[text_column].values  # Assuming 'target' is the label column\n",
    "#         self.labels = dataframe[label_column].values\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.encodings = self.tokenizer(list(self.text), truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "#         item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "#         return item\n",
    "\n",
    "\n",
    "# # Create tokenized dataset\n",
    "# #tokenized_dataset = TokenizedPandasDataset(df_data_raw, tokenizer, text_column='text', label_column='label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PURCHASE AUTHORIZED ON 05/14 DAIRY QUEEN # MESA AZ S CARD . Channel: in store. Amount: -7.6 [SEP] Dairy Queen [SEP] Dairy Queen', 'SEZZLE*DD DOORDASHMinneapol is MNSEZZLE*DD D. Channel: None. Amount: -11.7 [SEP] Sezzle [SEP] Ringling Market', 'DAVE INC LOS ANGELES CA 05/15. Channel: None. Amount: 125.0 [SEP] Dave Inc [SEP] Dave Inc', 'Online Banking transfer to CHK Confirmation# . Channel: None. Amount: -4.0 [SEP] Online Banking Transfer [SEP] Online Banking Transfer', 'Recurring Withdrawal Bill Payment - # Spotify USA 877- NY Card . Channel: online. Amount: -11.8 [SEP] Spotify [SEP] Food Stor', \"DUNKIN # , SHIPPENSBURG, PA. Channel: in store. Amount: -5.3 [SEP] Dunkin'' Donuts [SEP] Hyatt Resorts\", \" ZAXBY''S # HERNANDO MS**. Channel: in store. Amount: -18.1 [SEP] Zaxby''s [SEP] Brigit\", 'PURCHASE FLEX FINANCE NEW YORK NY . Channel: online. Amount: -813.5 [SEP] Flex Finance [SEP] Flex Finance'), tensor([1, 0, 1, 1, 0, 0, 0, 1])]\n",
      "[('NCIC INMATE PHONE SERVI 903- TX. Channel: online. Amount: -10.0 [SEP] Ncic Inmate Phone Serv [SEP] Top Ten Liquors Mp', \"POS PUR- 05/17 / 01:37 CASH APP*ALFRED SAN FRANCISCO CA. Channel: None. Amount: -7.7 [SEP] Cash App Alfred [SEP] Debbie''s Got The Tea\", 'Dbt Crd Aldi Westerville Oh. Channel: in store. Amount: -26.9 [SEP] Aldi [SEP] Aldi', 'AFFIRM * PAY P7AZI 05-15 855-423- CA DEBIT CARD RECURRING PYMT. Channel: None. Amount: -14.9 [SEP] Affirm [SEP] ExxonMobil', 'POS MAC BP# CAPL PARMA OH. Channel: in store. Amount: -22.5 [SEP] BP [SEP] Trail Drive Management', 'Transfer To Savings - . Channel: None. Amount: -400.0 [SEP] Savings [SEP] FloatMe', 'DEBIT CARD PURCHASE AT DD DOORDASH CHICK-, , CA ON FROM CARD#: . Channel: online. Amount: -19.6 [SEP] Chick-fil-A [SEP] Empower', 'SHELL OIL PEORIA AZ 05/14. Channel: in store. Amount: -86.2 [SEP] Shell [SEP] Empower'), tensor([0, 0, 1, 0, 0, 0, 0, 0])]\n",
      "[('POS Debit - Visa Check Card - MICROSOFT MICROSOFT XB REDMON SAMUEL L BREWER POS TRANSACTION. Channel: in store. Amount: -9.6 [SEP] Microsoft [SEP] Microsoft', 'PIZZA HUT DDA PIN POS PUR CD https://ipcha AR# . Channel: online. Amount: -15.5 [SEP] Pizza Hut [SEP] Pizza Hut', 'Google Hiya. Channel: online. Amount: -4.0 [SEP] Hiya [SEP] Express Cafe', \"WITHDRAWAL POS # MCDONALD''S F W JEFFERSON ST QUINCY FL. Channel: in store. Amount: -11.6 [SEP] McDonald''s [SEP] McDonald''s\", 'POS Withdrawal (FIP) SHEETZ SHEETZ MARENGO OH( ). Channel: in store. Amount: -5.5 [SEP] Sheetz [SEP] Sheetz', 'VOLA DES:VOLA ID: IGGBX58EG INDN:Dezmond Handy CO ID: WEB. Channel: in store. Amount: -100.0 [SEP] Vola [SEP] Mast Store Knoxville', 'NUGGET MARKET #10 ROSEVILLE CA 05/14. Channel: in store. Amount: -34.3 [SEP] Nugget Market [SEP] Chick-fil-A', 'Sp Bodycandy. Channel: in store. Amount: -12.5 [SEP] Bodycandy [SEP] Bodycandy'), tensor([1, 1, 0, 1, 1, 0, 0, 1])]\n",
      "[('Withdrawal # / EMPIRE PC KO OK 66 US CLAREMORE OK %% Card 16 # . Channel: in store. Amount: -3.2 [SEP] Empire Pc [SEP] Total Wine & More', 'SHELL OIL CHICAGO IL 05/14. Channel: in store. Amount: -4.7 [SEP] Shell [SEP] Boscovs', 'CHEVRON VENUS TX. Channel: in store. Amount: -19.9 [SEP] Chevron [SEP] Chevron', 'UBER *TRIP HELP.UBER.COM 800- CA. Channel: online. Amount: -24.0 [SEP] Uber [SEP] Uber', 'Cash App Transfer to Keyara Smith. Channel: None. Amount: -50.9 [SEP] Cash App Transfer [SEP] Cash App Transfer', 'COSTCO WHSE #0 05/15 # MOBILE PURCHASE COSTCO WHSE #06 AUSTIN TX. Channel: online. Amount: -9.2 [SEP] Costco [SEP] Costco', 'BKOFAMERICA ATM 05/15 # WITHDRWL S BAY PAVILLION AT CARSON CA. Channel: None. Amount: -20.0 [SEP] Bank of America ATM [SEP] Cash Withdrawal', 'Visa Checking INSTACASH REPAYMENT 888-659- NY Date 05/18/24 0 0 Card 15 # . Channel: None. Amount: -2.0 [SEP] MoneyLion [SEP] Fiber'), tensor([0, 0, 1, 1, 1, 1, 0, 0])]\n",
      "[('DBT CRD AFTERPAY 044- CA C# . Channel: None. Amount: -1.9 [SEP] Afterpay [SEP] Afterpay', 'FOODTOWN DAVIE FL 05/16. Channel: in store. Amount: -29.5 [SEP] Foodtown [SEP] Foodtown', 'BKOFAMERICA ATM 05/16 # DEPOSIT CONSTANT FRIENDSHI ABINGDON MD. Channel: None. Amount: 370.0 [SEP] Bank of America ATM [SEP] Bank of America ATM', 'PURCHASE AUTHORIZED ON 05/16 EL RANCHO #22 ODESSA TX P CARD . Channel: in store. Amount: -79.0 [SEP] El Rancho [SEP] Alta', 'RECURRING PAYMENT AUTHORIZED ON 05/15 ZIP* QUADPAY ANYWH 188- NY S CARD . Channel: None. Amount: -36.1 [SEP] Zip.co [SEP] Zip.co', 'POS PURCHASE POS TARGET T- Summerville SC. Channel: in store. Amount: -70.3 [SEP] Target [SEP] Target', ' PURCHASE-SIG SHELL OIL CYNTHIANA KY . Channel: in store. Amount: -20.0 [SEP] Shell [SEP] Loan', 'P2P BARCLAYS BANK DE . Channel: None. Amount: 35.0 [SEP] Barclays [SEP] Wells Fargo'), tensor([1, 1, 1, 0, 1, 1, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "# # Create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# i = 0\n",
    "# # Iterate through the DataLoader\n",
    "# for batch in dataloader:\n",
    "#     print(batch)\n",
    "#     tokenized_batch = tokenizer(batch[0], truncation=True, padding=True)\n",
    "#     i+=1\n",
    "#     if i>4:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_train = 1000\n",
    "\n",
    "# small_train_dataset = PandasDataset(df_data_raw[0:i_train])\n",
    "# small_val_dataset = PandasDataset(df_data_raw[i_train:2*i_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PandasDataset at 0x7f46914583d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_small_dataloader = DataLoader(small_train_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# model.train()\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in train_dataloader:\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#         outputs = model(**batch)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         lr_scheduler.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments\n",
    "\n",
    "# training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc2dc3a0853473b9729e2a0a801f28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import evaluate\n",
    "\n",
    "# metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "# val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "# test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=small_train_dataset,\n",
    "#     eval_dataset=small_eval_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't wantt o tokenize all the dataset at once, but rather tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.27.2\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (2.0.0.post304)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.27.2) (2023.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.27.2) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.27.2) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.21.0\n",
      "    Uninstalling accelerate-0.21.0:\n",
      "      Successfully uninstalled accelerate-0.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 0.8.3 requires accelerate<0.22.0,>=0.21.0, but you have accelerate 0.27.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pytorch-lightning<1.10.0,>=1.9.0, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post304 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchmetrics<0.12.0,>=0.11.0, but you have torchmetrics 1.0.3 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchvision<0.15.0, but you have torchvision 0.15.2a0+ab7b3e6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.27.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.40.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0.post304)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.10)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting umap-learn\n",
      "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (0.59.1)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from umap-learn) (4.66.4)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.2->umap-learn) (0.42.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.10/site-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
      "Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pynndescent, umap-learn\n",
      "Successfully installed pynndescent-0.5.13 umap-learn-0.5.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate==0.27.2\n",
    "%pip install sentence-transformers\n",
    "%pip install umap-learn\n",
    "#%pip install cleodata --extra-index-url \"https://aws:$(aws codeartifact get-authorization-token --domain meetcleo --domain-owner 878877078763 --query authorizationToken --output text)@meetcleo-878877078763.d.codeartifact.us-east-1.amazonaws.com/pypi/meetcleo-releases/simple/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install awswrangler\n",
    "# %pip install --upgrade sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import awswrangler as wr\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from io import StringIO\n",
    "#from fastparquet import ParquetFile\n",
    "#boto3.setup_default_session(profile_name='DataScientist-878877078763')\n",
    "# from cleodata.utils.secrets import get_secret\n",
    "#from cleodata.sources.sync.sync import SyncDataSource\n",
    "#redshift_source = SyncDataSource(\"data_exploration\", use_redshift=True, redshift_cluster=\"cleo-production-redshift\", redshift_db=\"cleo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 14:37:50.621423: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import umap\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0.post304\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_path = \"s3://cleo-data-science/transaction_enrichment/experimental_data/caste/trx-merchant-pair/trans_2024-05-14_2024-05-14_top_2001.parquet\"\n",
    "# s3_path = \"https://cleo-data-science.s3.amazonaws.com/transaction_enrichment/experimental_data/caste/trx-merchant-pair/trans_2024-05-18_2024-05-18_top_1_39000.parquet/\"\n",
    "# s3_path = \"s3://cleo-data-science/transaction_enrichment/experimental_data/caste/trx-merchant-pair/cons_2024-05-15_2024-05-18_1.parquet/\"\n",
    "\n",
    "# df_data_raw = wr.s3.read_parquet(path=s3_path)\n",
    "# df_data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>text</th>\n",
       "      <th>merchant_name</th>\n",
       "      <th>merchant_name2</th>\n",
       "      <th>description_combined_processed</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_m1</th>\n",
       "      <th>sent_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9711158815</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...</td>\n",
       "      <td>Hart Flamingofares</td>\n",
       "      <td>Hart-flamingofares</td>\n",
       "      <td>MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...</td>\n",
       "      <td>1</td>\n",
       "      <td>MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...</td>\n",
       "      <td>MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9740980806</td>\n",
       "      <td>-200.00</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...</td>\n",
       "      <td>Kids Unlimited</td>\n",
       "      <td>Kids Unlimited Inc</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...</td>\n",
       "      <td>1</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9796548131</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...</td>\n",
       "      <td>Edwardgurka Matcotools Rosharon</td>\n",
       "      <td>Edwardgurka-matco</td>\n",
       "      <td>CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...</td>\n",
       "      <td>1</td>\n",
       "      <td>CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...</td>\n",
       "      <td>CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9978142547</td>\n",
       "      <td>-25.04</td>\n",
       "      <td>Caseys [SEP] Casey''s Lincoln [SEP] Casey''s</td>\n",
       "      <td>Casey''s Lincoln</td>\n",
       "      <td>Casey''s</td>\n",
       "      <td>Caseys</td>\n",
       "      <td>1</td>\n",
       "      <td>Caseys |SEP| Casey''s Lincoln</td>\n",
       "      <td>Caseys |SEP| Casey''s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9694955604</td>\n",
       "      <td>-13.69</td>\n",
       "      <td>Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...</td>\n",
       "      <td>With</td>\n",
       "      <td>Hugo Insurance</td>\n",
       "      <td>Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...</td>\n",
       "      <td>1</td>\n",
       "      <td>Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...</td>\n",
       "      <td>Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id   amount                                               text  \\\n",
       "0      9711158815    -2.25  MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...   \n",
       "1      9740980806  -200.00  PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...   \n",
       "2      9796548131   -30.00  CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...   \n",
       "3      9978142547   -25.04       Caseys [SEP] Casey''s Lincoln [SEP] Casey''s   \n",
       "4      9694955604   -13.69  Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...   \n",
       "\n",
       "                     merchant_name      merchant_name2  \\\n",
       "0               Hart Flamingofares  Hart-flamingofares   \n",
       "1                   Kids Unlimited  Kids Unlimited Inc   \n",
       "2  Edwardgurka Matcotools Rosharon   Edwardgurka-matco   \n",
       "3                 Casey''s Lincoln            Casey''s   \n",
       "4                             With      Hugo Insurance   \n",
       "\n",
       "                      description_combined_processed  label  \\\n",
       "0  MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...      1   \n",
       "1  PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...      1   \n",
       "2  CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...      1   \n",
       "3                                             Caseys      1   \n",
       "4  Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...      1   \n",
       "\n",
       "                                             sent_m1  \\\n",
       "0  MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...   \n",
       "1  PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...   \n",
       "2  CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...   \n",
       "3                      Caseys |SEP| Casey''s Lincoln   \n",
       "4  Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...   \n",
       "\n",
       "                                             sent_m2  \n",
       "0  MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...  \n",
       "1  PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...  \n",
       "2  CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...  \n",
       "3                              Caseys |SEP| Casey''s  \n",
       "4  Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install s3fs --upgrade\n",
    "#import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'label'\n",
    "text_col = \"description_combined_processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4275000 475000 250000\n"
     ]
    }
   ],
   "source": [
    "df_ , df_test, y_, y_test = train_test_split(df_data_raw, df_data_raw[label_col], test_size = 0.05, random_state=1)\n",
    "df_train, df_val, y_train, y_val = train_test_split(df_, df_[label_col], test_size = 0.1, random_state=1)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "print(df_train.shape[0], df_val.shape[0], df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = \"description_combined_processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "df_train['len_sentence'] = df_train[text_col].apply(lambda x: len(x.split(' ')))\n",
    "print(df_train['len_sentence'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572f7a5f52ee44a5a832da32b6366163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184e590f978b415b87ef5af174a544cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e690c85908254dd586086b82489ed718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a55550fd1c64c1ea333173a312c1112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f35ddaed164490946851e9c681b601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "word_embedding_model = models.Transformer(\"bert-base-uncased\", max_seq_length=128)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4.275000e+06\n",
       "mean     7.572865e+00\n",
       "std      4.185147e+00\n",
       "min      1.000000e+00\n",
       "25%      4.000000e+00\n",
       "50%      7.000000e+00\n",
       "75%      1.100000e+01\n",
       "max      4.500000e+01\n",
       "Name: len_sentence, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('display.float_format', lambda x: '%.f' % x)\n",
    "#estimate maximum tokenized length\n",
    "df_train['len_sentence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(model.max_seq_length)\n",
    "model.max_seq_length = 128\n",
    "print(model.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>text</th>\n",
       "      <th>merchant_name</th>\n",
       "      <th>merchant_name2</th>\n",
       "      <th>description_combined_processed</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_m1</th>\n",
       "      <th>sent_m2</th>\n",
       "      <th>len_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10038658361</td>\n",
       "      <td>-40.00</td>\n",
       "      <td>Cleo Ai [SEP] Cleo [SEP] Financial Er</td>\n",
       "      <td>Cleo</td>\n",
       "      <td>Financial Er</td>\n",
       "      <td>Cleo Ai</td>\n",
       "      <td>0</td>\n",
       "      <td>Cleo Ai |SEP| Cleo</td>\n",
       "      <td>Cleo Ai |SEP| Financial Er</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10018806520</td>\n",
       "      <td>-15.00</td>\n",
       "      <td>951231 PURCHASE-SIG TODD''S PLACE EXP SHELBYVI...</td>\n",
       "      <td>Todd''s Place Express C</td>\n",
       "      <td>Grs Service Stat</td>\n",
       "      <td>951231 PURCHASE-SIG TODD''S PLACE EXP SHELBYVI...</td>\n",
       "      <td>0</td>\n",
       "      <td>951231 PURCHASE-SIG TODD''S PLACE EXP SHELBYVI...</td>\n",
       "      <td>951231 PURCHASE-SIG TODD''S PLACE EXP SHELBYVI...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9985997014</td>\n",
       "      <td>-20.05</td>\n",
       "      <td>DD DOORDASH ONTHEBORD 855-973-1040 CA [SEP] Do...</td>\n",
       "      <td>Doordash</td>\n",
       "      <td>Teds Bulletin</td>\n",
       "      <td>DD DOORDASH ONTHEBORD 855-973-1040 CA</td>\n",
       "      <td>0</td>\n",
       "      <td>DD DOORDASH ONTHEBORD 855-973-1040 CA |SEP| Do...</td>\n",
       "      <td>DD DOORDASH ONTHEBORD 855-973-1040 CA |SEP| Te...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10120071730</td>\n",
       "      <td>-10.05</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 7-ELEVEN Newport ...</td>\n",
       "      <td>7 Eleven</td>\n",
       "      <td>Zippy J</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 7-ELEVEN Newport ...</td>\n",
       "      <td>0</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 7-ELEVEN Newport ...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 7-ELEVEN Newport ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9873180985</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>CHECKCARD 0518 LION MART NO Memphis TN [SEP] L...</td>\n",
       "      <td>Lion Mart</td>\n",
       "      <td>Premier Cstore</td>\n",
       "      <td>CHECKCARD 0518 LION MART NO Memphis TN</td>\n",
       "      <td>0</td>\n",
       "      <td>CHECKCARD 0518 LION MART NO Memphis TN |SEP| L...</td>\n",
       "      <td>CHECKCARD 0518 LION MART NO Memphis TN |SEP| P...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  amount                                               text  \\\n",
       "0     10038658361  -40.00              Cleo Ai [SEP] Cleo [SEP] Financial Er   \n",
       "1     10018806520  -15.00  951231 PURCHASE-SIG TODD''S PLACE EXP SHELBYVI...   \n",
       "2      9985997014  -20.05  DD DOORDASH ONTHEBORD 855-973-1040 CA [SEP] Do...   \n",
       "3     10120071730  -10.05  PURCHASE AUTHORIZED ON 05/14 7-ELEVEN Newport ...   \n",
       "4      9873180985  -30.00  CHECKCARD 0518 LION MART NO Memphis TN [SEP] L...   \n",
       "\n",
       "             merchant_name    merchant_name2  \\\n",
       "0                     Cleo      Financial Er   \n",
       "1  Todd''s Place Express C  Grs Service Stat   \n",
       "2                 Doordash     Teds Bulletin   \n",
       "3                 7 Eleven           Zippy J   \n",
       "4                Lion Mart    Premier Cstore   \n",
       "\n",
       "                      description_combined_processed  label  \\\n",
       "0                                            Cleo Ai      0   \n",
       "1  951231 PURCHASE-SIG TODD''S PLACE EXP SHELBYVI...      0   \n",
       "2              DD DOORDASH ONTHEBORD 855-973-1040 CA      0   \n",
       "3  PURCHASE AUTHORIZED ON 05/14 7-ELEVEN Newport ...      0   \n",
       "4             CHECKCARD 0518 LION MART NO Memphis TN      0   \n",
       "\n",
       "                                             sent_m1  \\\n",
       "0                                 Cleo Ai |SEP| Cleo   \n",
       "1  951231 PURCHASE-SIG TODD''S PLACE EXP SHELBYVI...   \n",
       "2  DD DOORDASH ONTHEBORD 855-973-1040 CA |SEP| Do...   \n",
       "3  PURCHASE AUTHORIZED ON 05/14 7-ELEVEN Newport ...   \n",
       "4  CHECKCARD 0518 LION MART NO Memphis TN |SEP| L...   \n",
       "\n",
       "                                             sent_m2  len_sentence  \n",
       "0                         Cleo Ai |SEP| Financial Er             2  \n",
       "1  951231 PURCHASE-SIG TODD''S PLACE EXP SHELBYVI...             9  \n",
       "2  DD DOORDASH ONTHEBORD 855-973-1040 CA |SEP| Te...             5  \n",
       "3  PURCHASE AUTHORIZED ON 05/14 7-ELEVEN Newport ...            11  \n",
       "4  CHECKCARD 0518 LION MART NO Memphis TN |SEP| P...             7  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951231 PURCHASE-SIG TODD''S PLACE EXP SHELBYVILLE KY 00408192 951231\n"
     ]
    }
   ],
   "source": [
    "one_sent = df_train[text_col][0]\n",
    "print(df_train[text_col][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['label'].astype('float32')\n",
    "#df_train['true_label'] = df_train['true_label'].astype('float32')\n",
    "#train_examples = [InputExample(texts = [df_train.loc[i,'sentence'], df_train.loc[i,'merchant_name_combined']], label=df_train.loc[i,'true_label']  ) for i in range(df_train.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sentence_transformers.losses import CoSENTLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>text</th>\n",
       "      <th>merchant_name</th>\n",
       "      <th>merchant_name2</th>\n",
       "      <th>description_combined_processed</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_m1</th>\n",
       "      <th>sent_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9711158815</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...</td>\n",
       "      <td>Hart Flamingofares</td>\n",
       "      <td>Hart-flamingofares</td>\n",
       "      <td>MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...</td>\n",
       "      <td>1</td>\n",
       "      <td>MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...</td>\n",
       "      <td>MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9740980806</td>\n",
       "      <td>-200.00</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...</td>\n",
       "      <td>Kids Unlimited</td>\n",
       "      <td>Kids Unlimited Inc</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...</td>\n",
       "      <td>1</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9796548131</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...</td>\n",
       "      <td>Edwardgurka Matcotools Rosharon</td>\n",
       "      <td>Edwardgurka-matco</td>\n",
       "      <td>CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...</td>\n",
       "      <td>1</td>\n",
       "      <td>CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...</td>\n",
       "      <td>CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9978142547</td>\n",
       "      <td>-25.04</td>\n",
       "      <td>Caseys [SEP] Casey''s Lincoln [SEP] Casey''s</td>\n",
       "      <td>Casey''s Lincoln</td>\n",
       "      <td>Casey''s</td>\n",
       "      <td>Caseys</td>\n",
       "      <td>1</td>\n",
       "      <td>Caseys |SEP| Casey''s Lincoln</td>\n",
       "      <td>Caseys |SEP| Casey''s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9694955604</td>\n",
       "      <td>-13.69</td>\n",
       "      <td>Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...</td>\n",
       "      <td>With</td>\n",
       "      <td>Hugo Insurance</td>\n",
       "      <td>Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...</td>\n",
       "      <td>1</td>\n",
       "      <td>Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...</td>\n",
       "      <td>Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>10145501441</td>\n",
       "      <td>-6.35</td>\n",
       "      <td>GOOGLE *Playrix Games [SEP] Playrix Games [SEP...</td>\n",
       "      <td>Playrix Games</td>\n",
       "      <td>King</td>\n",
       "      <td>GOOGLE *Playrix Games</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGLE *Playrix Games |SEP| Playrix Games</td>\n",
       "      <td>GOOGLE *Playrix Games |SEP| King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>10145558378</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>CMS Vending Machines</td>\n",
       "      <td>Camsoda</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>0</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>10145558378</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>CMS Vending Machines</td>\n",
       "      <td>Rccl Applepay</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>0</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>10145558378</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>CMS Vending Machines</td>\n",
       "      <td>Area</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>0</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>10145558378</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>CMS Vending Machines</td>\n",
       "      <td>Hsm 78 Aro</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>0</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "      <td>Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         transaction_id   amount  \\\n",
       "0            9711158815    -2.25   \n",
       "1            9740980806  -200.00   \n",
       "2            9796548131   -30.00   \n",
       "3            9978142547   -25.04   \n",
       "4            9694955604   -13.69   \n",
       "...                 ...      ...   \n",
       "4999995     10145501441    -6.35   \n",
       "4999996     10145558378    -2.10   \n",
       "4999997     10145558378    -2.10   \n",
       "4999998     10145558378    -2.10   \n",
       "4999999     10145558378    -2.10   \n",
       "\n",
       "                                                      text  \\\n",
       "0        MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...   \n",
       "1        PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...   \n",
       "2        CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...   \n",
       "3             Caseys [SEP] Casey''s Lincoln [SEP] Casey''s   \n",
       "4        Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...   \n",
       "...                                                    ...   \n",
       "4999995  GOOGLE *Playrix Games [SEP] Playrix Games [SEP...   \n",
       "4999996  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...   \n",
       "4999997  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...   \n",
       "4999998  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...   \n",
       "4999999  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...   \n",
       "\n",
       "                           merchant_name      merchant_name2  \\\n",
       "0                     Hart Flamingofares  Hart-flamingofares   \n",
       "1                         Kids Unlimited  Kids Unlimited Inc   \n",
       "2        Edwardgurka Matcotools Rosharon   Edwardgurka-matco   \n",
       "3                       Casey''s Lincoln            Casey''s   \n",
       "4                                   With      Hugo Insurance   \n",
       "...                                  ...                 ...   \n",
       "4999995                    Playrix Games                King   \n",
       "4999996             CMS Vending Machines             Camsoda   \n",
       "4999997             CMS Vending Machines       Rccl Applepay   \n",
       "4999998             CMS Vending Machines                Area   \n",
       "4999999             CMS Vending Machines          Hsm 78 Aro   \n",
       "\n",
       "                            description_combined_processed  label  \\\n",
       "0        MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...      1   \n",
       "1        PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...      1   \n",
       "2        CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...      1   \n",
       "3                                                   Caseys      1   \n",
       "4        Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...      1   \n",
       "...                                                    ...    ...   \n",
       "4999995                              GOOGLE *Playrix Games      0   \n",
       "4999996  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...      0   \n",
       "4999997  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...      0   \n",
       "4999998  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...      0   \n",
       "4999999  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...      0   \n",
       "\n",
       "                                                   sent_m1  \\\n",
       "0        MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...   \n",
       "1        PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...   \n",
       "2        CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...   \n",
       "3                            Caseys |SEP| Casey''s Lincoln   \n",
       "4        Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...   \n",
       "...                                                    ...   \n",
       "4999995          GOOGLE *Playrix Games |SEP| Playrix Games   \n",
       "4999996  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...   \n",
       "4999997  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...   \n",
       "4999998  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...   \n",
       "4999999  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...   \n",
       "\n",
       "                                                   sent_m2  \n",
       "0        MOBILE PURCHASE 0505 HART-FLAMINGOFARES.COM TA...  \n",
       "1        PURCHASE AUTHORIZED ON 05/07 KIDS UNLIMITED IN...  \n",
       "2        CHECKCARD 0511 EDWARDGURKA-MATCO XXXXX96003 TX...  \n",
       "3                                    Caseys |SEP| Casey''s  \n",
       "4        Point Of Sale Withdrawal HUGO INSURANCE SOLNHT...  \n",
       "...                                                    ...  \n",
       "4999995                   GOOGLE *Playrix Games |SEP| King  \n",
       "4999996  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...  \n",
       "4999997  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...  \n",
       "4999998  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...  \n",
       "4999999  Signature POS Debit 05/03 VA RIDGEWAY CMSVEND*...  \n",
       "\n",
       "[5000000 rows x 9 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col1 = 'sent_m1'\n",
    "text_col2 = 'sent_m2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds_train = Dataset.from_pandas(df_train[[label_col,text_col1,text_col2]])\n",
    "ds_val = Dataset.from_pandas(df_val[[label_col,text_col1,text_col2]])\n",
    "ds_test = Dataset.from_pandas(df_test[[label_col,text_col1,text_col2]])\n",
    "\n",
    "ds_train = ds_train.rename_columns({label_col: \"score\",text_col1:\"sentence1\", text_col2:\"sentence2\"})\n",
    "ds_val = ds_val.rename_columns({label_col: \"score\",text_col1:\"sentence1\", text_col2:\"sentence2\"})\n",
    "ds_test = ds_test.rename_columns({label_col: \"score\",text_col1:\"sentence1\", text_col2:\"sentence2\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['score', 'sentence1', 'sentence2'],\n",
       "    num_rows: 250000\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = \"/home/sagemaker-user/logs\"\n",
    "\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(directory):\n",
    "    # Create the directory\n",
    "    os.makedirs(directory)\n",
    "    print(\"Directory created successfully!\")\n",
    "else:\n",
    "    print(\"Directory already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "from sentence_transformers import SentenceTransformerTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"/home/sagemaker-user/models/model11\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    evaluation_strategy=\"steps\", #eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=100,\n",
    "    logging_steps=500,\n",
    "    run_name=\"test1\",  # Will be used in W&B if `wandb` is installed\n",
    "    load_best_model_at_end= True,\n",
    "    logging_dir=\"/home/sagemaker-user/logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1,\n",
       " 'sentence1': 'Betmgm Online |SEP| BetMGM.com',\n",
       " 'sentence2': 'Betmgm Online |SEP| BetMGM'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=df_val[text_col1],\n",
    "    sentences2=df_val[text_col2],\n",
    "    scores=df_val[label_col],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    name=\"sts-dev\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_evaluator(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = CoSENTLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.14.344, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5001' max='100197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  5001/100197 1:39:36 < 31:36:43, 0.84 it/s, Epoch 0.15/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>3.296224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.264200</td>\n",
       "      <td>1.996672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.353200</td>\n",
       "      <td>1.591059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.793400</td>\n",
       "      <td>1.385806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.354700</td>\n",
       "      <td>1.016969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.394100</td>\n",
       "      <td>0.773053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.073000</td>\n",
       "      <td>0.867277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.821800</td>\n",
       "      <td>0.730691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.955300</td>\n",
       "      <td>0.662750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='775' max='3711' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 775/3711 01:31 < 05:45, 8.49 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acf9aefce854949a2dc11aeabe7e6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Create a trainer & train\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "    loss=train_loss,\n",
    "    #evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train()\n",
    "#resume_from_checkpoint=\"/home/sagemaker-user/models/model9/checkpoint-1600\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.41.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0.post200)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.10)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# # (Optional) Evaluate the trained model on the test set\n",
    "# test_evaluator = TripletEvaluator(\n",
    "#     anchors=df_test[\"sentence\"],\n",
    "#     positives=df_test[\"true_merchant_name_combined\"],\n",
    "#     negatives=test_dataset[\"true_label\"],\n",
    "#     name=\"pairs-test1\",\n",
    "# )\n",
    "# test_evaluator(model)\n",
    "\n",
    "# 8. Save the trained model\n",
    "model.save_pretrained(\"/home/sagemaker-user/models/model9final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_Pooling\t\t\t   scheduler.pt\n",
      "README.md\t\t\t   sentence_bert_config.json\n",
      "config.json\t\t\t   special_tokens_map.json\n",
      "config_sentence_transformers.json  tokenizer.json\n",
      "model.safetensors\t\t   tokenizer_config.json\n",
      "modules.json\t\t\t   trainer_state.json\n",
      "optimizer.pt\t\t\t   training_args.bin\n",
      "rng_state.pth\t\t\t   vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#!ls ./models/model1/checkpoint-600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded ./models/model1/checkpoint-600/config_sentence_transformers.json to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/config_sentence_transformers.json\n",
      "Successfully uploaded ./models/model1/checkpoint-600/config.json to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/config.json\n",
      "Successfully uploaded ./models/model1/checkpoint-600/model.safetensors to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/model.safetensors\n",
      "Successfully uploaded ./models/model1/checkpoint-600/tokenizer_config.json to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/tokenizer_config.json\n",
      "Successfully uploaded ./models/model1/checkpoint-600/special_tokens_map.json to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/special_tokens_map.json\n",
      "Successfully uploaded ./models/model1/checkpoint-600/vocab.txt to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/vocab.txt\n",
      "Successfully uploaded ./models/model1/checkpoint-600/tokenizer.json to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/tokenizer.json\n",
      "Successfully uploaded ./models/model1/checkpoint-600/sentence_bert_config.json to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/sentence_bert_config.json\n",
      "Successfully uploaded ./models/model1/checkpoint-600/modules.json to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/modules.json\n",
      "Successfully uploaded ./models/model1/checkpoint-600/README.md to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/README.md\n",
      "Successfully uploaded ./models/model1/checkpoint-600/training_args.bin to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/training_args.bin\n",
      "Successfully uploaded ./models/model1/checkpoint-600/optimizer.pt to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/optimizer.pt\n",
      "Successfully uploaded ./models/model1/checkpoint-600/scheduler.pt to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/scheduler.pt\n",
      "Successfully uploaded ./models/model1/checkpoint-600/rng_state.pth to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/rng_state.pth\n",
      "Successfully uploaded ./models/model1/checkpoint-600/trainer_state.json to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/trainer_state.json\n",
      "Successfully uploaded ./models/model1/checkpoint-600/1_Pooling/config.json to s3://cleo-data-science/transaction_enrichment/experimental_data/caste/pairs_model/model1-checkpoint600/1_Pooling/config.json\n"
     ]
    }
   ],
   "source": [
    "#copy \n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "\n",
    "def upload_directory_to_s3(local_directory, bucket_name, s3_directory):\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(local_path, local_directory)\n",
    "            s3_path = os.path.join(s3_directory, relative_path)\n",
    "\n",
    "            try:\n",
    "                s3_client.upload_file(local_path, bucket_name, s3_path)\n",
    "                print(f'Successfully uploaded {local_path} to s3://{bucket_name}/{s3_path}')\n",
    "            except FileNotFoundError:\n",
    "                print(f'The file {local_path} was not found')\n",
    "            except NoCredentialsError:\n",
    "                print('Credentials not available')\n",
    "            except PartialCredentialsError:\n",
    "                print('Incomplete credentials provided')\n",
    "\n",
    "# Example usage\n",
    "local_directory = \"/home/sagemaker-user/models/model4\"\"\n",
    "bucket_name = 'cleo-data-science'\n",
    "s3_directory = \"transaction_enrichment/experimental_data/caste/pairs_model/model4\"\n",
    "\n",
    "upload_directory_to_s3(local_directory, bucket_name, s3_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "#model = SentenceTransformer(\"./models/model1/checkpoint-600\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unique_merchants = df_train['merchant_name_combined'].tolist()\n",
    "embeddings_merchants = model.encode(list_unique_merchants)\n",
    "embeddings_merchants.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['pred_merchant'] = None\n",
    "df_test['pred_prob'] = 0.0\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n",
      "torch.Size([1000, 85500])\n",
      "1000 2000\n",
      "torch.Size([1000, 85500])\n",
      "2000 3000\n",
      "torch.Size([1000, 85500])\n",
      "3000 4000\n",
      "torch.Size([1000, 85500])\n",
      "4000 5000\n",
      "torch.Size([1000, 85500])\n"
     ]
    }
   ],
   "source": [
    "for istart in np.arange(0, df_test.shape[0]+1, batch_size):\n",
    "    iend = min(df_test.shape[0],istart + batch_size)\n",
    "    if iend> istart:\n",
    "        print(istart, iend)\n",
    "        tx_embeddings = model.encode(df_test['sentence'][istart:iend].tolist())\n",
    "        similarities = model.similarity(tx_embeddings, embeddings_merchants)\n",
    "        print(similarities.shape)\n",
    "        max_vals = torch.max(similarities, axis=1)\n",
    "        max_probs = max_vals[0]\n",
    "        ix_max_merchants = max_vals[1]\n",
    "        predicted_merchant = [list_unique_merchants[i] for i in ix_max_merchants]\n",
    "        df_test.loc[istart:iend-1,'pred_merchant'] =  predicted_merchant\n",
    "        df_test.loc[istart:iend-1,'pred_prob'] =  np.array(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9052\n"
     ]
    }
   ],
   "source": [
    "ntrue = df_test[df_test['pred_merchant'] == df_test['true_merchant_name_combined']].shape[0]\n",
    "\n",
    "precision = ntrue/df_test.shape[0]\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrue = df_test[(df_test['pred_merchant'] == df_test['true_merchant_name_combined']) & (df_test['pred_prob']>0.8)].shape[0]\n",
    "\n",
    "accuracy = ntrue/df_test.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp/tp + fp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>description_combined_processed</th>\n",
       "      <th>true_merchant_name_combined</th>\n",
       "      <th>merchant_name_combined</th>\n",
       "      <th>true_label</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_merchant</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9796686754</td>\n",
       "      <td>Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Channe...</td>\n",
       "      <td>Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Type: ...</td>\n",
       "      <td>Wal-Mart Super WAL-SAMS SPRINGFIELD MO</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Smith''s</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310292</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.799137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9799290885</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Synchrony</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232759</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.775473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9798904474</td>\n",
       "      <td>Walmart.com Bentonville AR XX SIG PURCH 05/13 ...</td>\n",
       "      <td>Walmart.com Bentonville AR XX SIG PURCH 05/13 ...</td>\n",
       "      <td>Walmart.com Bentonville AR XX SIG PURCH 05/13 ...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>QuikTrip</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075148</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.751793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9801927063</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Cash App</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078535</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.735269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9799263021</td>\n",
       "      <td>05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT...</td>\n",
       "      <td>05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT...</td>\n",
       "      <td>05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Marathon Petroleum</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257865</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.751371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>9807244423</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Spinstersis</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051089</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.772779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>9808452776</td>\n",
       "      <td>Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...</td>\n",
       "      <td>Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...</td>\n",
       "      <td>Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>K Stop Convenience</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018743</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.713919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>9798778036</td>\n",
       "      <td>Point of Sale Debit L341 TIME 04:30 PM DATE 05...</td>\n",
       "      <td>Point of Sale Debit L341 TIME 04:30 PM DATE 05...</td>\n",
       "      <td>Point of Sale Debit L341 TIME 04:30 PM DATE 05...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Ross Stores</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114881</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.766499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>9807593604</td>\n",
       "      <td>CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...</td>\n",
       "      <td>CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...</td>\n",
       "      <td>CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.751746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>9799287551</td>\n",
       "      <td>WM SUPERCENTER # GLENVILLE NY. Channel: in sto...</td>\n",
       "      <td>WM SUPERCENTER # GLENVILLE NY. Type: merchant....</td>\n",
       "      <td>WM SUPERCENTER # GLENVILLE NY</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Crenco</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015229</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.674671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     transaction_id                                           sentence  \\\n",
       "0        9796686754  Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Channe...   \n",
       "1        9799290885  PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "2        9798904474  Walmart.com Bentonville AR XX SIG PURCH 05/13 ...   \n",
       "3        9801927063  PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...   \n",
       "4        9799263021  05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT...   \n",
       "..              ...                                                ...   \n",
       "469      9807244423  PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "470      9808452776  Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...   \n",
       "471      9798778036  Point of Sale Debit L341 TIME 04:30 PM DATE 05...   \n",
       "472      9807593604  CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...   \n",
       "473      9799287551  WM SUPERCENTER # GLENVILLE NY. Channel: in sto...   \n",
       "\n",
       "                                             sentence2  \\\n",
       "0    Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Type: ...   \n",
       "1    PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "2    Walmart.com Bentonville AR XX SIG PURCH 05/13 ...   \n",
       "3    PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...   \n",
       "4    05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT...   \n",
       "..                                                 ...   \n",
       "469  PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "470  Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...   \n",
       "471  Point of Sale Debit L341 TIME 04:30 PM DATE 05...   \n",
       "472  CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...   \n",
       "473  WM SUPERCENTER # GLENVILLE NY. Type: merchant....   \n",
       "\n",
       "                        description_combined_processed  \\\n",
       "0               Wal-Mart Super WAL-SAMS SPRINGFIELD MO   \n",
       "1    PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "2    Walmart.com Bentonville AR XX SIG PURCH 05/13 ...   \n",
       "3    PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...   \n",
       "4      05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT    \n",
       "..                                                 ...   \n",
       "469  PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "470  Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...   \n",
       "471  Point of Sale Debit L341 TIME 04:30 PM DATE 05...   \n",
       "472  CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...   \n",
       "473                      WM SUPERCENTER # GLENVILLE NY   \n",
       "\n",
       "    true_merchant_name_combined merchant_name_combined  true_label     label  \\\n",
       "0                       Walmart               Smith''s           0  0.310292   \n",
       "1                       Walmart              Synchrony           0  0.232759   \n",
       "2                       Walmart               QuikTrip           0  0.075148   \n",
       "3                       Walmart               Cash App           0  0.078535   \n",
       "4                       Walmart     Marathon Petroleum           0  0.257865   \n",
       "..                          ...                    ...         ...       ...   \n",
       "469                     Walmart            Spinstersis           0  0.051089   \n",
       "470                     Walmart     K Stop Convenience           0  0.018743   \n",
       "471                     Walmart            Ross Stores           0  0.114881   \n",
       "472                     Walmart                   Lyft           0  0.116438   \n",
       "473                     Walmart                 Crenco           0  0.015229   \n",
       "\n",
       "         pred_merchant  pred_prob  \n",
       "0    Wal Wal-martsuper   0.799137  \n",
       "1    Wal Wal-martsuper   0.775473  \n",
       "2    Wal Wal-martsuper   0.751793  \n",
       "3    Wal Wal-martsuper   0.735269  \n",
       "4    Wal Wal-martsuper   0.751371  \n",
       "..                 ...        ...  \n",
       "469  Wal Wal-martsuper   0.772779  \n",
       "470  Wal Wal-martsuper   0.713919  \n",
       "471  Wal Wal-martsuper   0.766499  \n",
       "472  Wal Wal-martsuper   0.751746  \n",
       "473  Wal Wal-martsuper   0.674671  \n",
       "\n",
       "[474 rows x 10 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_match = df_test[df_test['pred_merchant'] != df_test['true_merchant_name_combined']]\n",
    "df_no_match.reset_index(drop=True, inplace=True)\n",
    "df_no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>description_combined_processed</th>\n",
       "      <th>true_merchant_name_combined</th>\n",
       "      <th>merchant_name_combined</th>\n",
       "      <th>true_label</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_merchant</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9796686754</td>\n",
       "      <td>Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Channe...</td>\n",
       "      <td>Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Type: ...</td>\n",
       "      <td>Wal-Mart Super WAL-SAMS SPRINGFIELD MO</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Smith''s</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310292</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.799137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9799066977</td>\n",
       "      <td>ONLINE TRANSFER FROM MCDONALD J WELLS FARGO CL...</td>\n",
       "      <td>ONLINE TRANSFER FROM MCDONALD J WELLS FARGO CL...</td>\n",
       "      <td>ONLINE TRANSFER FROM MCDONALD J WELLS FARGO CL...</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Empower</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416453</td>\n",
       "      <td>McDonald''s</td>\n",
       "      <td>0.939226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9813217231</td>\n",
       "      <td>POS PURCHASE POS WM SUPERCENTER GREENVILLE PA....</td>\n",
       "      <td>POS PURCHASE POS WM SUPERCENTER GREENVILLE PA....</td>\n",
       "      <td>POS PURCHASE POS WM SUPERCENTER GREENVILLE PA</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>RaceTrac</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288263</td>\n",
       "      <td>McDonald''s</td>\n",
       "      <td>0.630497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9795670664</td>\n",
       "      <td>POS PURCH : WM SUPERCENTER # GA BAXLEY WM SUPE...</td>\n",
       "      <td>POS PURCH : WM SUPERCENTER # GA BAXLEY WM SUPE...</td>\n",
       "      <td>POS PURCH : WM SUPERCENTER # GA BAXLEY WM SUPE...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Synchrony</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>U.s. Retailers</td>\n",
       "      <td>0.642287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>9800470341</td>\n",
       "      <td>ZELLE TO FEDRA ON 05/14 REF #RP0S842CWR WALMAR...</td>\n",
       "      <td>ZELLE TO FEDRA ON 05/14 REF #RP0S842CWR WALMAR...</td>\n",
       "      <td>ZELLE TO FEDRA ON 05/14 REF #RP0S842CWR WALMART</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030782</td>\n",
       "      <td>Zelle</td>\n",
       "      <td>0.705138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transaction_id                                           sentence  \\\n",
       "0        9796686754  Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Channe...   \n",
       "13       9799066977  ONLINE TRANSFER FROM MCDONALD J WELLS FARGO CL...   \n",
       "18       9813217231  POS PURCHASE POS WM SUPERCENTER GREENVILLE PA....   \n",
       "36       9795670664  POS PURCH : WM SUPERCENTER # GA BAXLEY WM SUPE...   \n",
       "269      9800470341  ZELLE TO FEDRA ON 05/14 REF #RP0S842CWR WALMAR...   \n",
       "\n",
       "                                             sentence2  \\\n",
       "0    Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Type: ...   \n",
       "13   ONLINE TRANSFER FROM MCDONALD J WELLS FARGO CL...   \n",
       "18   POS PURCHASE POS WM SUPERCENTER GREENVILLE PA....   \n",
       "36   POS PURCH : WM SUPERCENTER # GA BAXLEY WM SUPE...   \n",
       "269  ZELLE TO FEDRA ON 05/14 REF #RP0S842CWR WALMAR...   \n",
       "\n",
       "                        description_combined_processed  \\\n",
       "0               Wal-Mart Super WAL-SAMS SPRINGFIELD MO   \n",
       "13   ONLINE TRANSFER FROM MCDONALD J WELLS FARGO CL...   \n",
       "18       POS PURCHASE POS WM SUPERCENTER GREENVILLE PA   \n",
       "36   POS PURCH : WM SUPERCENTER # GA BAXLEY WM SUPE...   \n",
       "269    ZELLE TO FEDRA ON 05/14 REF #RP0S842CWR WALMART   \n",
       "\n",
       "    true_merchant_name_combined merchant_name_combined  true_label     label  \\\n",
       "0                       Walmart               Smith''s           0  0.310292   \n",
       "13                  Wells Fargo                Empower           0  0.416453   \n",
       "18                      Walmart               RaceTrac           0  0.288263   \n",
       "36                      Walmart              Synchrony           0  0.000095   \n",
       "269                     Walmart        Bank of America           0  0.030782   \n",
       "\n",
       "         pred_merchant  pred_prob  \n",
       "0    Wal Wal-martsuper   0.799137  \n",
       "13         McDonald''s   0.939226  \n",
       "18         McDonald''s   0.630497  \n",
       "36      U.s. Retailers   0.642287  \n",
       "269              Zelle   0.705138  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_match.drop_duplicates(subset = ['true_merchant_name_combined','pred_merchant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ONLINE TRANSFER FROM MCDONALD J WELLS FARGO CLEAR ACCESS BANKING XXXXXX REF #IB0N78QNRB ON 05/14/24. Channel: None. Amount: 90.0'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_match.loc[13,'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZELLE TO FEDRA ON 05/14 REF #RP0S842CWR WALMART. Channel: None. Amount: -98.77'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_match.loc[269,'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4526, 10)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true_merchant_name_combined\n",
       "Amazon         12848\n",
       "Cash App       12840\n",
       "Earnin         12825\n",
       "Wells Fargo    12812\n",
       "McDonald''s    12811\n",
       "Zelle          12781\n",
       "Walmart         8583\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['true_merchant_name_combined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['true_merchant_name_combined'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true_merchant_name_combined\n",
       "Zelle          796\n",
       "Wells Fargo    757\n",
       "Amazon         756\n",
       "Cash App       746\n",
       "McDonald''s    745\n",
       "Earnin         729\n",
       "Walmart        471\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['true_merchant_name_combined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true_merchant_name_combined\n",
       "Earnin         1446\n",
       "McDonald''s    1444\n",
       "Wells Fargo    1431\n",
       "Zelle          1423\n",
       "Cash App       1414\n",
       "Amazon         1396\n",
       "Walmart         946\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['true_merchant_name_combined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_merchant_name_combined</th>\n",
       "      <th>pred_merchant</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>0.961568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McDonald''s</td>\n",
       "      <td>McDonald''s</td>\n",
       "      <td>0.974988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cash App</td>\n",
       "      <td>Cash App</td>\n",
       "      <td>0.975234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McDonald''s</td>\n",
       "      <td>McDonald''s</td>\n",
       "      <td>0.980123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.799137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>0.940395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Zelle</td>\n",
       "      <td>Zelle</td>\n",
       "      <td>0.979735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.674671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Zelle</td>\n",
       "      <td>Zelle</td>\n",
       "      <td>0.980085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Zelle</td>\n",
       "      <td>Zelle</td>\n",
       "      <td>0.980246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true_merchant_name_combined      pred_merchant  pred_prob\n",
       "0                    Wells Fargo        Wells Fargo   0.961568\n",
       "1                    McDonald''s        McDonald''s   0.974988\n",
       "2                       Cash App           Cash App   0.975234\n",
       "3                    McDonald''s        McDonald''s   0.980123\n",
       "4                        Walmart  Wal Wal-martsuper   0.799137\n",
       "...                          ...                ...        ...\n",
       "4995                 Wells Fargo        Wells Fargo   0.940395\n",
       "4996                       Zelle              Zelle   0.979735\n",
       "4997                     Walmart  Wal Wal-martsuper   0.674671\n",
       "4998                       Zelle              Zelle   0.980085\n",
       "4999                       Zelle              Zelle   0.980246\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['true_merchant_name_combined','pred_merchant','pred_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test['pred_prob'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>description_combined_processed</th>\n",
       "      <th>true_merchant_name_combined</th>\n",
       "      <th>merchant_name_combined</th>\n",
       "      <th>true_label</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_merchant</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9796686754</td>\n",
       "      <td>Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Channe...</td>\n",
       "      <td>Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Type: ...</td>\n",
       "      <td>Wal-Mart Super WAL-SAMS SPRINGFIELD MO</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Smith''s</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310292</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.799137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9799290885</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Synchrony</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232759</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.775473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9798904474</td>\n",
       "      <td>Walmart.com Bentonville AR XX SIG PURCH 05/13 ...</td>\n",
       "      <td>Walmart.com Bentonville AR XX SIG PURCH 05/13 ...</td>\n",
       "      <td>Walmart.com Bentonville AR XX SIG PURCH 05/13 ...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>QuikTrip</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075148</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.751793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9801927063</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Cash App</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078535</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.735269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9799263021</td>\n",
       "      <td>05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT...</td>\n",
       "      <td>05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT...</td>\n",
       "      <td>05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Marathon Petroleum</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257865</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.751371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>9807244423</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Spinstersis</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051089</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.772779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>9808452776</td>\n",
       "      <td>Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...</td>\n",
       "      <td>Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...</td>\n",
       "      <td>Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>K Stop Convenience</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018743</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.713919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>9798778036</td>\n",
       "      <td>Point of Sale Debit L341 TIME 04:30 PM DATE 05...</td>\n",
       "      <td>Point of Sale Debit L341 TIME 04:30 PM DATE 05...</td>\n",
       "      <td>Point of Sale Debit L341 TIME 04:30 PM DATE 05...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Ross Stores</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114881</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.766499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>9807593604</td>\n",
       "      <td>CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...</td>\n",
       "      <td>CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...</td>\n",
       "      <td>CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.751746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9799287551</td>\n",
       "      <td>WM SUPERCENTER # GLENVILLE NY. Channel: in sto...</td>\n",
       "      <td>WM SUPERCENTER # GLENVILLE NY. Type: merchant....</td>\n",
       "      <td>WM SUPERCENTER # GLENVILLE NY</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Crenco</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015229</td>\n",
       "      <td>Wal Wal-martsuper</td>\n",
       "      <td>0.674671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_id                                           sentence  \\\n",
       "4         9796686754  Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Channe...   \n",
       "11        9799290885  PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "12        9798904474  Walmart.com Bentonville AR XX SIG PURCH 05/13 ...   \n",
       "17        9801927063  PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...   \n",
       "28        9799263021  05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT...   \n",
       "...              ...                                                ...   \n",
       "4960      9807244423  PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "4965      9808452776  Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...   \n",
       "4971      9798778036  Point of Sale Debit L341 TIME 04:30 PM DATE 05...   \n",
       "4981      9807593604  CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...   \n",
       "4997      9799287551  WM SUPERCENTER # GLENVILLE NY. Channel: in sto...   \n",
       "\n",
       "                                              sentence2  \\\n",
       "4     Wal-Mart Super WAL-SAMS SPRINGFIELD MO. Type: ...   \n",
       "11    PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "12    Walmart.com Bentonville AR XX SIG PURCH 05/13 ...   \n",
       "17    PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...   \n",
       "28    05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT...   \n",
       "...                                                 ...   \n",
       "4960  PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "4965  Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...   \n",
       "4971  Point of Sale Debit L341 TIME 04:30 PM DATE 05...   \n",
       "4981  CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...   \n",
       "4997  WM SUPERCENTER # GLENVILLE NY. Type: merchant....   \n",
       "\n",
       "                         description_combined_processed  \\\n",
       "4                Wal-Mart Super WAL-SAMS SPRINGFIELD MO   \n",
       "11    PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "12    Walmart.com Bentonville AR XX SIG PURCH 05/13 ...   \n",
       "17    PURCHASE AUTHORIZED ON 05/11 WALMART.COM 800-9...   \n",
       "28      05/13 22:02 WAL-MART # JONESBORO AR CKCD DEBIT    \n",
       "...                                                 ...   \n",
       "4960  PURCHASE AUTHORIZED ON 05/14 WM SUPERC Wal-Mar...   \n",
       "4965  Walmart.com 05/14 #XXXXX REFUND Walmart.com Be...   \n",
       "4971  Point of Sale Debit L341 TIME 04:30 PM DATE 05...   \n",
       "4981  CHECKCARD WALMART STA ELENA LA LIBERTAD XXXXX ...   \n",
       "4997                      WM SUPERCENTER # GLENVILLE NY   \n",
       "\n",
       "     true_merchant_name_combined merchant_name_combined  true_label     label  \\\n",
       "4                        Walmart               Smith''s           0  0.310292   \n",
       "11                       Walmart              Synchrony           0  0.232759   \n",
       "12                       Walmart               QuikTrip           0  0.075148   \n",
       "17                       Walmart               Cash App           0  0.078535   \n",
       "28                       Walmart     Marathon Petroleum           0  0.257865   \n",
       "...                          ...                    ...         ...       ...   \n",
       "4960                     Walmart            Spinstersis           0  0.051089   \n",
       "4965                     Walmart     K Stop Convenience           0  0.018743   \n",
       "4971                     Walmart            Ross Stores           0  0.114881   \n",
       "4981                     Walmart                   Lyft           0  0.116438   \n",
       "4997                     Walmart                 Crenco           0  0.015229   \n",
       "\n",
       "          pred_merchant  pred_prob  \n",
       "4     Wal Wal-martsuper   0.799137  \n",
       "11    Wal Wal-martsuper   0.775473  \n",
       "12    Wal Wal-martsuper   0.751793  \n",
       "17    Wal Wal-martsuper   0.735269  \n",
       "28    Wal Wal-martsuper   0.751371  \n",
       "...                 ...        ...  \n",
       "4960  Wal Wal-martsuper   0.772779  \n",
       "4965  Wal Wal-martsuper   0.713919  \n",
       "4971  Wal Wal-martsuper   0.766499  \n",
       "4981  Wal Wal-martsuper   0.751746  \n",
       "4997  Wal Wal-martsuper   0.674671  \n",
       "\n",
       "[483 rows x 10 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['pred_prob']<0.85][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    Deposit Debit Ca Earnin CEEEE_B Palo Alto CA D...\n",
       "101    Zelle payment from AMY HAYES for \\\"vanishing b...\n",
       "102    EARNIN CHGFC_B PALO ALTO CA 05/14. Channel: No...\n",
       "103    PURCHASE AUTHORIZED ON 05/13 MCDONALD''S F IRV...\n",
       "104    Debit Card Credit EARNIN CCHGA_B PALO ALTO CA....\n",
       "105    Zelle payment from SUSAN BRODBECK BACsggj269q0...\n",
       "106    POS Payment McDonalds 154-XXX VA # . Channel: ...\n",
       "107    ONLINE TRANSFER FROM HUDSON A WAY2SAVE SAVINGS...\n",
       "108    EARNIN CDHJA_B PALO ALTO CA 05/14. Channel: No...\n",
       "109    Earnin CEGJA_B Palo Alto CA. Channel: None. Am...\n",
       "110    ONLINE TRANSFER FROM BENNETT T WAY2SAVE SAVING...\n",
       "111    Zelle payment from ALEXIS GAUDET BACxe32r3prx....\n",
       "112    PURCHASE AMZN Mktp US*SY1BN Amzn.com/billWA XX...\n",
       "113    CASH APP*ERIC LOLA BAR. Channel: None. Amount:...\n",
       "114    Zelle payment from SHAVONNE MORENO BACpwpbspl0...\n",
       "115    McDonalds 05-12 BROOKSVILLE FL DEBIT CARD PURC...\n",
       "116    CHECKCARD CASH APP*WE DESIG XXXXX CA XXXXX XXX...\n",
       "117    AMZN Mktp US*WN8Q06S Amzn.com/bill WA 05/14. C...\n",
       "118    ONLINE TRANSFER FROM CANNATA-FILERA T WAY2SAVE...\n",
       "119    Point Of Sale Withdrawal MCDONALD''S F597 DAWS...\n",
       "120    ATM/POS Share Deposit Earnin CCEGE_B - Earnin ...\n",
       "121    Debit Purchase -visa Mcdonald''s F212 Hamilton...\n",
       "122    XX DDA CREDIT ADJ Earnin CJAIB_B Palo Alto CA ...\n",
       "123    Debit CardWithdrawal: VISA Debit Sig.WM SUPE...\n",
       "124    CHECKCARD MCDONALD''S M CULVER CITY CA XXXXX X...\n",
       "125    Zelle payment from ELIJAH MUHAMMAD ST PHAR WFC...\n",
       "126    Debit Card Purchase 05/11 10:22a # AMAZON.COM*...\n",
       "127    PURCHASE AUTHORIZED ON 05/13 Amazon Prime*NY07...\n",
       "128    AMAZON.COM SERVI DES:INTERNET ID:XXXXXXXXXX IN...\n",
       "129    ZELLE FROM GEIER TONNIE ON 05/14 REF # PP0S83X...\n",
       "130    POS PURCHASE WAL-MART # WEST MONROE ***** 05/1...\n",
       "131    ONLINE TRANSFER FROM VILLAFUERTE J WAY2SAVE SA...\n",
       "132    Zelle payment from JOSEFINA ESPINAL for \\\"pago...\n",
       "133    Cash App Transfer to Alan Hernande. Channel: N...\n",
       "134    MCDONALD''S F CLERMONT FL 05/13. Channel: in s...\n",
       "135    Withdrawal Debit Card DEBIT CARD/WAL-MART # SO...\n",
       "136    ZELLE TO RODRIGUEZ ROBERT ON 05/13 REF #PP0S82...\n",
       "137    Point Of Sale Deposit Earnin / CGEDJ_B Palo Al...\n",
       "138    POS PURCHASE POS WM SUPERCENTER GREENVILLE PA....\n",
       "139    PURCHASE AMAZON MAR* XXX-XX HTTPSAMAZON.CWA XX...\n",
       "140    POS DEBIT 05/14 7:28 WAL WAL MART SUPER LUBBOC...\n",
       "141    ONLINE TRANSFER TO HOLLEY V WELLS FARGO CLEAR ...\n",
       "142    Payment to CASH APP*APRIL B ROBER. Channel: No...\n",
       "143    PURCHASE AUTHORIZED ON 05/13 Amazon Prime*A87L...\n",
       "144    AMAZON.COM*8L3G SEATTLE /WA US CARD PURCHASE. ...\n",
       "145    Earnin CCDFE_B Palo Alto CA. Channel: None. Am...\n",
       "146    SAVE AS YOU GO TRANSFER DEBIT TO XXXXXXXXXXX ....\n",
       "147    Zelle Transaction H . Channel: None. Amount: 3...\n",
       "148    EARNIN CIJJC_B PALO ALTO CA 05/14. Channel: No...\n",
       "149    SAVE AS YOU GO TRANSFER DEBIT TO XXXXXXXXXXX ....\n",
       "Name: sentence, dtype: string"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sentence'][100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00816036,  0.27537555,  0.14324246, ...,  0.0999889 ,\n",
       "        -0.0035936 ,  0.07809736],\n",
       "       [ 0.02443847, -0.07863627,  0.01445072, ...,  0.02271993,\n",
       "         0.03442278,  0.02410999],\n",
       "       [-0.01848849,  0.26305526,  0.12530893, ...,  0.09496655,\n",
       "         0.00565742,  0.07274164],\n",
       "       ...,\n",
       "       [ 0.02032459, -0.06118753,  0.01493401, ..., -0.00625443,\n",
       "         0.10024939,  0.12695931],\n",
       "       [-0.01988285, -0.1525213 ,  0.0045229 , ..., -0.01461221,\n",
       "         0.02463034,  0.0660398 ],\n",
       "       [-0.01051987, -0.06855395,  0.00723861, ..., -0.00558885,\n",
       "         0.0144608 ,  0.05602989]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(df_test['sentence'][istart:istart+batch_size].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.loc[istart:istart+batch_size-1,'pred_merchant'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.loc[0:100,'label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[0:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "istart+batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(predicted_merchant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_embedding = model.encode(df_test['sentence'][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 85500])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.9616, 0.9750]),\n",
       "indices=tensor([117,  17]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([117,  17])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Wells Fargo\n",
       "1         McDonald''s\n",
       "2            Cash App\n",
       "3             Verizon\n",
       "4            Smith''s\n",
       "            ...      \n",
       "4995    Chumba Casino\n",
       "4996            Zelle\n",
       "4997           Crenco\n",
       "4998          Empower\n",
       "4999            Zelle\n",
       "Name: merchant_name_combined, Length: 5000, dtype: string"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['merchant_name_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert.ipynb Cell 48\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://yd6plnil3hw8unc.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m matched_merchants \u001b[39m=\u001b[39m similarities\u001b[39m.\u001b[39mmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://yd6plnil3hw8unc.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m matched_merchants\n",
      "\u001b[0;31mNameError\u001b[0m: name 'similarities' is not defined"
     ]
    }
   ],
   "source": [
    "matched_merchants = similarities.max(axis=1)\n",
    "matched_merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9629, 0.9737])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score = matched_merchants[0]\n",
    "similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matched_merchants' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert.ipynb Cell 50\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://yd6plnil3hw8unc.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m matched_merchants\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matched_merchants' is not defined"
     ]
    }
   ],
   "source": [
    "matched_merchants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "print(sentence_transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerModelCardData\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name microsoft/mpnet-base. Creating a new one with mean pooling.\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fc4151b2bb4649a3f733f06a1ca31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/69.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b1ff8f2b0e400191f659296292ab16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.57M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adaf006de9cd4f0c9365293f64593dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.61M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4548ca60d147e2bf4180cc9717277c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/942069 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6481230ea1e844bca7c04d944de42a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/19657 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99381b567f484ed58f1bb044b75ece6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/19656 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load a model to finetune with 2. (Optional) model card data\n",
    "model = SentenceTransformer(\n",
    "    \"microsoft/mpnet-base\",\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"MPNet base trained on AllNLI triplets\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Load a dataset to finetune on\n",
    "dataset = load_dataset(\"sentence-transformers/all-nli\",'pair-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'score'],\n",
       "        num_rows: 942069\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'score'],\n",
       "        num_rows: 19657\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'score'],\n",
       "        num_rows: 19656\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'A person on a horse jumps over a broken down airplane.',\n",
       " 'sentence2': 'A person is training his horse for a competition.',\n",
       " 'score': 0.5}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataloader = DataLoader(train_examples, shuffle=True, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loss = losses.CosineSimilarityLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert.ipynb Cell 39\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://yd6plnil3hw8unc.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v2_sbert.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_loss\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.14.343, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='668' max='668' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [668/668 04:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(train_objectives = [(train_dataloader, train_loss)], epochs = 1 , warmup_steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_descriptions = df_val['sentence'].tolist()\n",
    "merchants = df_val['merchant_name_combined'].tolist()\n",
    "trx_embeddings = model.encode(trx_descriptions)\n",
    "merchants_embeddings = model.encode(merchants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9500, 768)\n",
      "(9500, 768)\n"
     ]
    }
   ],
   "source": [
    "print(trx_embeddings.shape)\n",
    "print(merchants_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## look into numba\n",
    "cosine_similarity(trx_embeddings, merchants_embeddings).shape\n",
    "df_val['cos_similarity']=np.diag(cosine_similarity(trx_embeddings, merchants_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>description_combined_processed</th>\n",
       "      <th>true_merchant_name_combined</th>\n",
       "      <th>merchant_name_combined</th>\n",
       "      <th>true_label</th>\n",
       "      <th>label</th>\n",
       "      <th>cos_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9798760350</td>\n",
       "      <td>Debit Purchase Wal-mart Super Cbrookings Sd 05...</td>\n",
       "      <td>Debit Purchase Wal-mart Super Cbrookings Sd 05...</td>\n",
       "      <td>Debit Purchase Wal-mart Super Cbrookings Sd 05...</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Exotic S Shop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328529</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9806775557</td>\n",
       "      <td>MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...</td>\n",
       "      <td>MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...</td>\n",
       "      <td>MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...</td>\n",
       "      <td>Cash App</td>\n",
       "      <td>Acorns</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265679</td>\n",
       "      <td>-0.010028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9798728894</td>\n",
       "      <td>MONEY TRANSFER AUTHORIZED ON 05/13 FROM Earnin...</td>\n",
       "      <td>MONEY TRANSFER AUTHORIZED ON 05/13 FROM Earnin...</td>\n",
       "      <td>MONEY TRANSFER AUTHORIZED ON 05/13 FROM Earnin...</td>\n",
       "      <td>Earnin</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207873</td>\n",
       "      <td>-0.003231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9799291124</td>\n",
       "      <td>MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...</td>\n",
       "      <td>MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...</td>\n",
       "      <td>MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...</td>\n",
       "      <td>Cash App</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.001403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9799976650</td>\n",
       "      <td>Instant Pmt from Earnin RDBFA_B on 05/14 Ref# ...</td>\n",
       "      <td>Instant Pmt from Earnin RDBFA_B on 05/14 Ref# ...</td>\n",
       "      <td>Instant Pmt from Earnin RDBFA_B on 05/14 Ref# ...</td>\n",
       "      <td>Earnin</td>\n",
       "      <td>Venmo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054398</td>\n",
       "      <td>-0.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>9799636891</td>\n",
       "      <td>PURCHASE RETURN AUTHORIZED ON 05/13 AMZN Mktp ...</td>\n",
       "      <td>PURCHASE RETURN AUTHORIZED ON 05/13 AMZN Mktp ...</td>\n",
       "      <td>PURCHASE RETURN AUTHORIZED ON 05/13 AMZN Mktp ...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>TGI Friday''s</td>\n",
       "      <td>0</td>\n",
       "      <td>0.102636</td>\n",
       "      <td>0.001885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>9799365097</td>\n",
       "      <td>AMZN Mktp US GE69A,2YL3 Amzn com WA,05-13-24,C...</td>\n",
       "      <td>AMZN Mktp US GE69A,2YL3 Amzn com WA,05-13-24,C...</td>\n",
       "      <td>AMZN Mktp US GE69A,2YL3 Amzn com WA,05-13-24,C...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840733</td>\n",
       "      <td>0.995985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>9814848095</td>\n",
       "      <td>ONLINE TRANSFER FROM NAME N WELLS FARGO CLEAR ...</td>\n",
       "      <td>ONLINE TRANSFER FROM NAME N WELLS FARGO CLEAR ...</td>\n",
       "      <td>ONLINE TRANSFER FROM NAME N WELLS FARGO CLEAR ...</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888943</td>\n",
       "      <td>0.988127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>9799827250</td>\n",
       "      <td>MCDONALD''S F ROCKY RIVER OH 05/13. Channel: i...</td>\n",
       "      <td>MCDONALD''S F ROCKY RIVER OH 05/13. Type: merc...</td>\n",
       "      <td>MCDONALD''S F ROCKY RIVER OH 05/13</td>\n",
       "      <td>McDonald''s</td>\n",
       "      <td>Coca-Cola</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085374</td>\n",
       "      <td>-0.001350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>9809070494</td>\n",
       "      <td>ONLINE TRANSFER FROM BELMAN A WELLS FARGO CLEA...</td>\n",
       "      <td>ONLINE TRANSFER FROM BELMAN A WELLS FARGO CLEA...</td>\n",
       "      <td>ONLINE TRANSFER FROM BELMAN A WELLS FARGO CLEA...</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Albertsons</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344464</td>\n",
       "      <td>-0.001449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9500 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_id                                           sentence  \\\n",
       "0         9798760350  Debit Purchase Wal-mart Super Cbrookings Sd 05...   \n",
       "1         9806775557  MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...   \n",
       "2         9798728894  MONEY TRANSFER AUTHORIZED ON 05/13 FROM Earnin...   \n",
       "3         9799291124  MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...   \n",
       "4         9799976650  Instant Pmt from Earnin RDBFA_B on 05/14 Ref# ...   \n",
       "...              ...                                                ...   \n",
       "9495      9799636891  PURCHASE RETURN AUTHORIZED ON 05/13 AMZN Mktp ...   \n",
       "9496      9799365097  AMZN Mktp US GE69A,2YL3 Amzn com WA,05-13-24,C...   \n",
       "9497      9814848095  ONLINE TRANSFER FROM NAME N WELLS FARGO CLEAR ...   \n",
       "9498      9799827250  MCDONALD''S F ROCKY RIVER OH 05/13. Channel: i...   \n",
       "9499      9809070494  ONLINE TRANSFER FROM BELMAN A WELLS FARGO CLEA...   \n",
       "\n",
       "                                              sentence2  \\\n",
       "0     Debit Purchase Wal-mart Super Cbrookings Sd 05...   \n",
       "1     MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...   \n",
       "2     MONEY TRANSFER AUTHORIZED ON 05/13 FROM Earnin...   \n",
       "3     MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...   \n",
       "4     Instant Pmt from Earnin RDBFA_B on 05/14 Ref# ...   \n",
       "...                                                 ...   \n",
       "9495  PURCHASE RETURN AUTHORIZED ON 05/13 AMZN Mktp ...   \n",
       "9496  AMZN Mktp US GE69A,2YL3 Amzn com WA,05-13-24,C...   \n",
       "9497  ONLINE TRANSFER FROM NAME N WELLS FARGO CLEAR ...   \n",
       "9498  MCDONALD''S F ROCKY RIVER OH 05/13. Type: merc...   \n",
       "9499  ONLINE TRANSFER FROM BELMAN A WELLS FARGO CLEA...   \n",
       "\n",
       "                         description_combined_processed  \\\n",
       "0     Debit Purchase Wal-mart Super Cbrookings Sd 05...   \n",
       "1     MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...   \n",
       "2     MONEY TRANSFER AUTHORIZED ON 05/13 FROM Earnin...   \n",
       "3     MONEY TRANSFER AUTHORIZED ON 05/13 CASH APP*JE...   \n",
       "4     Instant Pmt from Earnin RDBFA_B on 05/14 Ref# ...   \n",
       "...                                                 ...   \n",
       "9495  PURCHASE RETURN AUTHORIZED ON 05/13 AMZN Mktp ...   \n",
       "9496  AMZN Mktp US GE69A,2YL3 Amzn com WA,05-13-24,C...   \n",
       "9497  ONLINE TRANSFER FROM NAME N WELLS FARGO CLEAR ...   \n",
       "9498                 MCDONALD''S F ROCKY RIVER OH 05/13   \n",
       "9499  ONLINE TRANSFER FROM BELMAN A WELLS FARGO CLEA...   \n",
       "\n",
       "     true_merchant_name_combined merchant_name_combined  true_label     label  \\\n",
       "0                        Walmart          Exotic S Shop           0  0.328529   \n",
       "1                       Cash App                 Acorns           0  0.265679   \n",
       "2                         Earnin                 PayPal           0  0.207873   \n",
       "3                       Cash App            Wells Fargo           0  0.008904   \n",
       "4                         Earnin                  Venmo           0  0.054398   \n",
       "...                          ...                    ...         ...       ...   \n",
       "9495                      Amazon          TGI Friday''s           0  0.102636   \n",
       "9496                      Amazon                 Amazon           1  0.840733   \n",
       "9497                 Wells Fargo            Wells Fargo           1  0.888943   \n",
       "9498                 McDonald''s              Coca-Cola           0  0.085374   \n",
       "9499                 Wells Fargo             Albertsons           0  0.344464   \n",
       "\n",
       "      cos_similarity  \n",
       "0           0.000262  \n",
       "1          -0.010028  \n",
       "2          -0.003231  \n",
       "3           0.001403  \n",
       "4          -0.010100  \n",
       "...              ...  \n",
       "9495        0.001885  \n",
       "9496        0.995985  \n",
       "9497        0.988127  \n",
       "9498       -0.001350  \n",
       "9499       -0.001449  \n",
       "\n",
       "[9500 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v1_sbert.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://yd6plnil3hw8unc.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v1_sbert.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://yd6plnil3hw8unc.studio.us-east-1.sagemaker.aws/home/sagemaker-user/exploration/MERCHANTS/Biencoder_v1_sbert.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data[['label', 'true_label','cos_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer = umap.UMAP(n_epochs=400,  n_neighbors=150, min_dist=0.1)\n",
    "# reducer.fit(merchants_embeddings\n",
    "# )\n",
    "# embedding_2d = reducer.transform(merchants_embeddings)\n",
    "# fig = px.scatter(embedding_2d, x=0, y=1,opacity=0.05, height=500, hover_name=names)\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
